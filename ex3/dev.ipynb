{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36764bitfea43b0e40d34535bec856bc28b38585",
   "display_name": "Python 3.6.7 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import struct\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist ref:http://yann.lecun.com/exdb/mnist/\n",
    "# struct ref:https://www.cnblogs.com/gala/archive/2011/09/22/2184801.html\n",
    "# numpy ref:numpy.org.cn/article/basics/numpy_matrices_vectors.html\n",
    "def LoadImages(file):\n",
    "    try:\n",
    "        F = open(file, 'rb')\n",
    "    except IOError:\n",
    "        print(\"open error\")\n",
    "        F.close()\n",
    "\n",
    "    f = F.read()\n",
    "\n",
    "    offset=0\n",
    "    fmt = '>iiii'\n",
    "    magic, images, rows, columns = struct.unpack_from(fmt, f, offset)\n",
    "\n",
    "    offset += struct.calcsize(fmt)\n",
    "    fmt = '>' + str(rows * columns) + 'B'\n",
    "\n",
    "    images = 10 # for test\n",
    "\n",
    "    # for CNN\n",
    "    # ImageSet = np.empty((images, rows, columns))\n",
    "    # for i in range(images):\n",
    "    #     ImageSet[i] = np.array(struct.unpack_from(fmt, f, offset)).reshape((rows, columns))\n",
    "    #     offset += struct.calcsize(fmt)\n",
    "\n",
    "    # for simple softmax\n",
    "    ImageSet = np.empty((images, rows * columns))\n",
    "    for i in range(images):\n",
    "        ImageSet[i] = np.array(struct.unpack_from(fmt, f, offset)).reshape((rows*columns))\n",
    "        offset += struct.calcsize(fmt)\n",
    "\n",
    "    F.close()\n",
    "\n",
    "    return ImageSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadLabels(file):\n",
    "    try:\n",
    "        F = open(file, 'rb')\n",
    "    except IOError:\n",
    "        print(\"open error\")\n",
    "        F.close()\n",
    "\n",
    "    f = F.read()\n",
    "\n",
    "    offset=0\n",
    "    fmt = '>ii'\n",
    "\n",
    "    magic, items = struct.unpack_from(fmt, f, offset)\n",
    "\n",
    "    offset += struct.calcsize(fmt)\n",
    "    fmt = '>B'\n",
    "\n",
    "    items = 10 # for test\n",
    "\n",
    "    LabelSet = np.zeros((items, 10))\n",
    "    for i in range(items):\n",
    "        LabelSet[i][struct.unpack_from(fmt, f, offset)[0]] = 1\n",
    "        offset += struct.calcsize(fmt)\n",
    "\n",
    "    F.close()\n",
    "\n",
    "    return LabelSet\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# test\n",
    "# im = LoadImages('train-images.idx3-ubyte')\n",
    "# la = LoadLabels('train-labels.idx1-ubyte')\n",
    "# plt.ion()\n",
    "# for i in range(10):\n",
    "#     plt.imshow(im[i], cmap='Greys')\n",
    "#     print(la[i])\n",
    "#     plt.pause(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training set\n",
    "TrainImages_np = LoadImages('train-images.idx3-ubyte')\n",
    "TrainLabels_np = LoadLabels('train-labels.idx1-ubyte')\n",
    "\n",
    "TrainImages = torch.from_numpy(TrainImages_np)\n",
    "TrainLabels = torch.from_numpy(TrainLabels_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)\ntensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n"
    }
   ],
   "source": [
    "# test\n",
    "print(TrainImages)\n",
    "print(TrainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax with torch\n",
    "class SoftmaxNet(nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(SoftmaxNet, self).__init__()\n",
    "        self.hidden = nn.Linear(n_feature, n_hidden)\n",
    "        self.predict = nn.Linear(n_hidden, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))\n",
    "        x = self.predict(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "SoftmaxNet(\n  (hidden): Linear(in_features=784, out_features=520, bias=True)\n  (predict): Linear(in_features=520, out_features=10, bias=True)\n)\n"
    }
   ],
   "source": [
    "net = SoftmaxNet(28*28, 520, 10)\n",
    "print(net)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.12205237\n[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n[4.9467782e-20 4.1360080e-14 1.1239714e-04 2.6005052e-06 5.2913076e-21\n 9.9988496e-01 9.2716762e-19 2.3027789e-24 1.4922628e-17 1.2042262e-28]\n[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n[9.3351982e-14 1.3328730e-07 1.7368343e-02 9.5789212e-01 9.1107521e-12\n 2.4739409e-02 8.8541912e-23 1.3120361e-18 5.1082639e-26 2.1963773e-24]\n[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n[7.03766184e-25 1.68134685e-14 4.01520006e-12 9.99952793e-01\n 4.72466745e-05 1.44424633e-13 6.50952337e-16 7.16692691e-23\n 1.18336616e-17 3.09392226e-21]\n[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n[9.9496310e-07 9.9991834e-01 1.4470901e-06 4.9041599e-05 3.7820318e-08\n 4.4823221e-08 1.1787675e-22 3.0305968e-05 2.9974734e-14 7.9499407e-11]\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n[3.57777696e-12 2.28750197e-09 1.31199045e-11 5.63690095e-10\n 4.34593971e-15 9.99999881e-01 1.15539132e-16 9.13181668e-16\n 1.17780427e-12 7.37193560e-08]\n[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n[6.3160729e-23 9.9998116e-01 2.2123553e-12 5.2190826e-14 1.8514449e-05\n 3.1418691e-07 2.1722468e-09 1.2885880e-13 1.1755649e-12 3.3917646e-18]\n[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n[4.4374614e-16 2.0105936e-08 7.7043007e-17 6.5520311e-08 5.1183087e-17\n 2.1423994e-14 9.5264946e-27 2.7462435e-19 9.9999738e-01 2.4546862e-06]\n[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n[1.0253429e-18 5.4104428e-17 6.8842759e-03 9.2228047e-09 1.1194276e-20\n 9.9311572e-01 1.5342902e-35 2.0552683e-29 3.4454974e-23 3.7261598e-27]\n[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n[2.29534010e-07 8.42336357e-01 7.56199790e-12 3.42166051e-02\n 4.33007841e-07 3.01261061e-05 3.94187517e-14 2.62771191e-08\n 1.23405948e-01 1.03778775e-05]\n[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n[2.2422063e-07 3.8640372e-11 3.2077194e-09 1.5851733e-09 6.3985062e-01\n 5.8500427e-10 3.6014912e-01 1.7696510e-16 2.3132514e-09 5.2278046e-18]\n0.09856034\n[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n[1.3788884e-21 6.8928721e-15 1.7238638e-04 2.2277474e-10 8.0711398e-14\n 9.9982762e-01 4.9116302e-29 5.8550514e-26 2.7406694e-20 5.9220006e-30]\n[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n[9.9249074e-16 6.5030545e-09 3.3950284e-02 1.2902390e-08 1.2848309e-05\n 9.6603686e-01 3.4198925e-33 8.8974891e-21 8.9673736e-29 1.9524722e-26]\n[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n[1.6410791e-28 2.1997245e-17 6.5471602e-15 9.2235176e-05 9.9990773e-01\n 1.8881904e-16 2.7791816e-27 3.5795445e-26 4.4406759e-21 2.3484653e-24]\n[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n[2.4989868e-07 9.9600935e-01 3.1730235e-06 8.9170044e-07 3.9737900e-03\n 4.1946748e-08 4.2266501e-29 1.2435727e-05 3.9395189e-15 3.0015764e-11]\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n[5.9231851e-13 2.8188105e-09 1.9891738e-11 1.6499725e-12 7.8265472e-08\n 9.9999988e-01 7.8868058e-26 2.4109652e-16 1.2546739e-14 8.5768610e-09]\n[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n[2.1146103e-30 2.2610952e-07 3.1233633e-18 1.1427113e-22 9.9999976e-01\n 9.3407389e-13 1.0272985e-28 3.4393140e-21 1.9745882e-20 3.2237153e-25]\n[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n[1.28875504e-14 3.64436601e-05 8.74827317e-15 9.28534973e-08\n 5.34063127e-10 5.02413996e-12 8.05584052e-31 8.29732796e-18\n 9.99846220e-01 1.17202166e-04]\n[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n[1.3894668e-20 5.5221837e-18 4.0650386e-02 1.8068434e-12 3.0353764e-10\n 9.5934963e-01 0.0000000e+00 3.7766388e-31 7.3450925e-26 1.4151805e-28]\n[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n[3.1273331e-09 9.9987674e-01 2.2758751e-13 6.0955444e-05 2.1290023e-05\n 1.5831083e-06 1.3909927e-19 2.8081648e-10 3.9362702e-05 1.5041256e-07]\n[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n[5.2658450e-26 5.8313078e-29 2.4068352e-27 4.2386382e-27 1.0000000e+00\n 1.4378285e-27 4.9205166e-39 3.7827575e-35 4.0720760e-28 8.3110105e-36]\n0.119876124\n[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n[4.3500003e-24 1.2418252e-17 1.0000000e+00 4.9386911e-13 9.6722348e-17\n 1.2442669e-10 1.7873835e-31 9.3751664e-29 5.6520010e-23 3.2460755e-33]\n[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n[7.1645042e-23 2.4704288e-16 1.0000000e+00 2.5250334e-15 2.9729504e-13\n 1.4446036e-17 2.0624311e-40 2.9203793e-28 4.5773265e-36 1.3345003e-34]\n[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n[3.2241969e-28 3.2541050e-17 2.9503466e-11 1.2774979e-04 9.9987221e-01\n 5.2562581e-20 4.4534649e-27 4.7867759e-26 5.0853339e-21 2.3626510e-24]\n[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n[3.1890150e-07 9.8697817e-01 8.1267096e-03 1.6166482e-06 4.8795394e-03\n 1.1809092e-11 5.4683603e-29 1.3533707e-05 4.2039783e-15 2.0905612e-11]\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n[1.6422442e-08 7.4396135e-05 4.5167501e-03 6.0338820e-08 1.3706773e-03\n 9.9393481e-01 1.5188698e-21 7.5545386e-12 3.1284947e-10 1.0324163e-04]\n[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n[5.3052708e-30 4.0777141e-07 4.4559786e-12 3.5119254e-22 9.9999964e-01\n 9.8554672e-19 2.4880509e-28 5.4725756e-21 4.5625790e-20 2.3436592e-25]\n[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n[1.4343741e-14 4.5693592e-05 9.4966465e-12 1.3806424e-07 4.6636933e-10\n 3.3220666e-15 1.3160491e-30 7.4266484e-18 9.9986148e-01 9.2655675e-05]\n[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n[2.4311476e-29 7.3943684e-27 1.0000000e+00 3.6852181e-21 6.1932790e-20\n 6.4651197e-21 0.0000000e+00 1.9592675e-40 8.8528018e-35 1.6841468e-38]\n[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n[3.9984642e-09 9.9984670e-01 1.8645710e-11 8.2436978e-05 2.0779640e-05\n 1.8033228e-08 1.6787417e-19 3.0705674e-10 4.9986917e-05 1.2748698e-07]\n[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n[1.0968434e-25 8.5633213e-29 5.8378250e-23 7.9054178e-27 1.0000000e+00\n 7.5366244e-32 1.0622267e-38 8.2394514e-35 8.2911891e-28 6.0619370e-36]\n0.11824587\n[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n[2.8660748e-24 8.4553740e-18 1.0000000e+00 3.2856132e-13 7.2410471e-17\n 4.1298128e-11 1.1605110e-31 6.2859826e-29 3.6640197e-23 2.1301605e-33]\n[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n[4.1502155e-23 1.5293492e-16 1.0000000e+00 1.5467932e-15 2.0227255e-13\n 3.7286779e-18 1.1717938e-40 1.7702391e-28 2.6561355e-36 7.6289141e-35]\n[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n[2.98418680e-28 3.06932778e-17 3.70059781e-11 1.18605065e-04\n 9.99881387e-01 3.05190387e-20 4.04748314e-27 4.46746075e-26\n 4.61901855e-21 2.20225313e-24]\n[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n[3.0157858e-07 9.8392040e-01 1.0886945e-02 1.5640760e-06 5.1776078e-03\n 6.3248972e-12 5.1837145e-29 1.3095049e-05 3.9618353e-15 1.9997386e-11]\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n[8.7739309e-08 4.2970441e-04 8.3345510e-02 3.5682072e-07 1.0850164e-02\n 9.0479892e-01 7.4932765e-21 4.4751286e-11 1.8038286e-09 5.7520327e-04]\n[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n[4.5069586e-30 3.4105946e-07 7.0003773e-12 3.0683251e-22 9.9999964e-01\n 2.9742561e-19 1.9989306e-28 4.5823391e-21 3.8472687e-20 1.9278120e-25]\n[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n[1.46464567e-14 4.90194216e-05 1.51994008e-11 1.44323124e-07\n 5.37954958e-10 1.70577824e-15 1.35076705e-30 7.58399056e-18\n 9.99853253e-01 9.76052761e-05]\n[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n[1.3193135e-29 4.2142771e-27 1.0000000e+00 2.0366774e-21 3.9355315e-20\n 1.2976563e-21 0.0000000e+00 1.0611753e-40 4.6646359e-35 8.9980275e-39]\n[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n[3.9479029e-09 9.9984467e-01 2.6394002e-11 8.2723396e-05 2.2592381e-05\n 1.0476302e-08 1.6512121e-19 3.1095068e-10 4.9872870e-05 1.2854778e-07]\n[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n[9.5758204e-26 7.6992793e-29 8.2410418e-23 7.1087076e-27 1.0000000e+00\n 3.1713054e-32 9.1997514e-39 7.4904388e-35 7.3373251e-28 5.3054184e-36]\n0.13040078\n[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n[6.7431614e-27 2.0913334e-20 1.0000000e+00 8.5284635e-16 4.0119917e-19\n 2.6967651e-17 2.1376893e-34 1.9316347e-31 8.8611199e-26 3.6644289e-36]\n[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n[1.7693632e-26 9.4506503e-20 1.0000000e+00 1.2628344e-18 2.2715203e-16\n 1.0459289e-25 3.7835059e-44 1.2432905e-31 1.3094097e-39 1.8506049e-38]\n[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n[2.0779747e-28 2.0270640e-17 1.9941386e-09 8.3188235e-05 9.9991679e-01\n 8.1381731e-23 2.1152853e-27 3.2613935e-26 2.6922493e-21 1.3396902e-24]\n[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n[9.6107932e-08 2.7664614e-01 7.1915352e-01 6.6459774e-07 4.1942131e-03\n 2.3838895e-15 1.5499615e-29 5.3160343e-06 1.3004764e-15 5.5310374e-12]\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n[4.1634278e-14 2.4244473e-10 1.0000000e+00 4.6055092e-13 5.2818372e-08\n 3.2281979e-16 8.1976264e-28 5.5403730e-17 1.8893959e-15 2.0458929e-10]\n[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n[1.8155245e-30 7.1619894e-08 2.0610051e-08 1.7854628e-22 9.9999988e-01\n 5.8975369e-25 3.6566916e-29 1.4773640e-21 1.5615516e-20 3.7199821e-26]\n[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n[1.2557002e-14 4.9191720e-05 8.2383753e-09 1.7490554e-07 9.9620823e-10\n 4.1553302e-19 1.1677247e-30 6.3658757e-18 9.9986768e-01 8.2955514e-05]\n[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n[1.7050762e-33 5.7097955e-31 1.0000000e+00 3.5093099e-25 1.2028985e-23\n 1.1983692e-30 0.0000000e+00 1.4012985e-44 5.0447417e-39 6.0255834e-43]\n[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n[4.6476409e-09 9.9975282e-01 5.1702913e-09 1.1738886e-04 4.8567712e-05\n 2.3272590e-11 1.7156004e-19 5.0607984e-10 8.1063183e-05 1.5159242e-07]\n[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n[4.1346915e-26 3.2596822e-29 3.4514473e-20 4.4459542e-27 1.0000000e+00\n 2.3356411e-36 3.5578239e-39 5.5891456e-35 4.2128283e-28 1.7730434e-36]\n"
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "TrainImages = torch.tensor(TrainImages, dtype=torch.float32)\n",
    "TrainLabels = torch.tensor(TrainLabels, dtype=torch.float32)\n",
    "\n",
    "for t in range(5):\n",
    "    prediction = net(TrainImages)\n",
    "    loss = loss_func(prediction, TrainLabels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # for test\n",
    "    print(loss.data.numpy())\n",
    "    # plt.ion()\n",
    "    for i in range(10):\n",
    "        print((TrainLabels.numpy())[i])\n",
    "        print((prediction.detach().numpy())[i])\n",
    "        # plt.imshow(((TrainImages.numpy())[i]).reshape((28, 28)), cmap='Greys')\n",
    "        # plt.pause(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}